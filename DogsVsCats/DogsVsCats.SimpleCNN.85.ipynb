{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach for meassurement\n",
    "\n",
    "For doing some EDA I will use a simple CNN with two convultion blocks and a flatten dense layer with a softmax activation as ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications import InceptionV3, VGG16\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "%matplotlib inline\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown on the description we have 30 unique labels under the Animal column. There a chance of applying the keras common structure for DataAugmentation.\n",
    "\n",
    "For now IÂ´m going to jump directly into the mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "TRAIN_PATH = 'dataset/train/'\n",
    "TEST_PATH = 'dataset/test1/'\n",
    "EPOCHS = 2000\n",
    "IMG_PATH =  TRAIN_PATH+str(train.Image_id[0])\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, CHANNELS)\n",
    "NB_CLASSES = 30\n",
    "REG = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )\n",
    "\n",
    "        \n",
    "def read_img(img_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    \"\"\"\n",
    "    Transforms an image from the given path to an array of the size given.\n",
    "    \n",
    "    The ouput will be the image with a shape of (img_width, img_height, 3).\n",
    "    Its assumed that images are RGB.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img        \n",
    "\n",
    "def get_labels(df):\n",
    "    label_cols = list(set(train.columns) - set(['Image_name']))\n",
    "    label_cols.sort()\n",
    "    return df.iloc[0][2:].index[train.iloc[0][2:] == 1]\n",
    "\n",
    "def load_pictures(directory, dataset):\n",
    "    label_enconder = LabelEncoder()\n",
    "    dataset.Animal = label_enconder.fit_transform(dataset.Animal)\n",
    "    \n",
    "    y = []\n",
    "    X = []\n",
    "    for sample in log_progress(dataset.values, every=10):\n",
    "        X.append(read_img(directory + sample[0]))\n",
    "        y.append(sample[1]) \n",
    "    return X, y\n",
    "\n",
    "def load_test_pictures(directory, dataset):\n",
    "    X = []\n",
    "    for sample in log_progress(dataset.values, every=10):\n",
    "        X.append(read_img(directory + sample[0]))\n",
    "    return X\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        horizontal_flip = False,\n",
    "        vertical_flip = True,\n",
    "        shear_range = 5.,\n",
    "        fill_mode = \"nearest\",\n",
    "        zoom_range = 0.2,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range=0.2,\n",
    "        rotation_range=20)\n",
    "\n",
    "def create_val_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        horizontal_flip = False,\n",
    "        vertical_flip = True,\n",
    "        fill_mode = \"nearest\",\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range=0.2)\n",
    "\n",
    "def normailize_data(data):\n",
    "    return np.array(data).astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN:\n",
    "    @staticmethod\n",
    "    def build(input_shape = (IMG_WIDTH, IMG_WIDTH, CHANNELS), classes=NB_CLASSES):                             \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(BatchNormalization(input_shape=input_shape))\n",
    "        model.add(Conv2D(32, (3, 3), padding='same', activation='relu' ))\n",
    "        model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        \n",
    "        model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu'))        \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))        \n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(Dense(1024, activation='relu'))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(20, kernel_size=5, padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(50, kernel_size=5, padding='same',activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))        \n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "class InceptionV3Ext:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        v3_model = InceptionV3(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "        for layer in v3_model.layers: layer.trainable = False\n",
    "            \n",
    "            \n",
    "        #Adding custom Layers \n",
    "        x = v3_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "        predictions = Dense(classes, activation=\"softmax\")(x)\n",
    "\n",
    "        # creating the final model \n",
    "        return Model(input = v3_model.input, output = predictions)\n",
    "\n",
    "class VGG16Ext:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = VGG16(weights = \"imagenet\", include_top=False, input_shape = INPUT_SHAPE)\n",
    "        for layer in model.layers: layer.trainable = False\n",
    "            \n",
    "            \n",
    "        #Adding custom Layers \n",
    "        model_ext = model.output\n",
    "        model_ext = Dense(1024, activation='relu')(model_ext)\n",
    "        model_ext = Dense(1024, activation='relu')(model_ext)\n",
    "        \n",
    "        preductions = Dense(classes, activation=\"softmax\")(model_ext)\n",
    "\n",
    "        # creating the final model \n",
    "        return Model(inputs = model.input, outputs = predictionsictions)    \n",
    "\n",
    "class BasicCNN:\n",
    "    @staticmethod\n",
    "    def build(input_shape = (IMG_WIDTH, IMG_WIDTH, CHANNELS), classes=NB_CLASSES):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=input_shape))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(classes, activation='softmax'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "X, y = load_pictures(TRAIN_PATH, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genererating de final training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normailize_data(X)\n",
    "\n",
    "Xtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "ytrain = to_categorical(ytrain, NB_CLASSES)\n",
    "yvalid = to_categorical(yvalid, NB_CLASSES)\n",
    "\n",
    "print('Xtrain shape: ', Xtrain.shape)\n",
    "print('Xvalid shape: ', Xvalid.shape)\n",
    "print('ytrain shape: ', ytrain.shape)\n",
    "print('yvalid shape: ', yvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xtrain[7], interpolation='nearest')\n",
    "plt.title(ytrain[7])\n",
    "plt.show()\n",
    "\n",
    "print(type(ytrain[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xvalid[7], interpolation='nearest')\n",
    "plt.title(yvalid[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom net... or something yacnn bla bla\n",
    "\n",
    "3 simple block of\n",
    "\n",
    "Input (128, 128, 3)\n",
    "Conv2D 32 3,3\n",
    "Conv2D 32 3,3\n",
    "Pooling\n",
    "Dropout\n",
    "\n",
    "Conv2D 64 3,3\n",
    "Conv2D 64 3,3\n",
    "Pooling\n",
    "Dropout\n",
    "\n",
    "Conv2D 128 3,3\n",
    "Conv2D 128 3,3\n",
    "Pooling\n",
    "Dropout\n",
    "\n",
    "Flatten\n",
    "Dense 512\n",
    "Dropout\n",
    "Dense - classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "#model = CustomCNN.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "#model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model = InceptionV3Ext.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "#model = VGG16Ext.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(lr=0.00001, decay=1e-3, momentum=0.9, nesterov=False)\n",
    "adam_optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):    \n",
    "    model.compile(optimizer=adam_optimizer, \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    early_stops = EarlyStopping(patience=20, monitor='val_acc', verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath='weights.best.eda.hdf5', verbose=1, save_best_only=True)\n",
    "    \n",
    "    callbacks = [checkpointer, early_stops]\n",
    "    \n",
    "    h = model.fit(Xtrain, ytrain, \n",
    "                  validation_data=(Xvalid, yvalid), \n",
    "                  epochs=EPOCHS, \n",
    "                  batch_size=10, \n",
    "                  callbacks=callbacks, \n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(h.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.save_weights(\"final_ouput.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_col = train.Animal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = load_test_pictures(TEST_PATH, test)\n",
    "\n",
    "X_test = normailize_data(test_img)     \n",
    "\n",
    "del test_img\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model.load_weights('final_ouput.hdf5')\n",
    "pred_test = model.predict(X_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.8f}'.format\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['image_id'] = test.Image_id\n",
    "label_df = pd.DataFrame(data=pred_test, columns=labels_col)\n",
    "subm = pd.concat([subm, label_df], axis=1)\n",
    "subm = subm.set_index('image_id')\n",
    "subm = subm.reindex(sorted(subm.columns), axis=1)\n",
    "subm.to_csv('submit.csv', index=True)\n",
    "subm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log_loss: {}'.format(log_loss(pred_test, y_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
